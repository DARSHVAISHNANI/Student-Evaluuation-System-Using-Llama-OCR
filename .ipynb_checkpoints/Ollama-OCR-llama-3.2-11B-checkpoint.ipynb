{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f880453-7fda-4f91-b2a7-a2862fa36c6b",
   "metadata": {},
   "source": [
    "# Ollama-OCR Implementation using llama 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc423ac-ca7c-446f-bdd0-efcf1e54e8a5",
   "metadata": {},
   "source": [
    "##### Github for referrence: https://github.com/imanoop7/Ollama-OCR/blob/main/src/ollama_ocr/ocr_processor.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c5604b-91f7-41b1-86d0-f631782b5b2f",
   "metadata": {},
   "source": [
    "### installation of Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251072c6-b02b-4e47-a7af-aed51c922bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ollama-ocr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5540d3be-539f-4c7e-9880-a3f60eeaaf9a",
   "metadata": {},
   "source": [
    "### installation of Sentence-Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e23057-aa17-4b75-9764-7d7b07ed2bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ac33b0-05ce-4a86-b8eb-21ed17e83f52",
   "metadata": {},
   "source": [
    "### Install the llama 3.2 llb model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ae444c-de56-4630-b80f-87f9105c04b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama3.2-vision:11b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5622deed-b7e1-495e-94cd-ddf248e9aff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a607ce58-4f97-444a-be53-3ab453cf5b59",
   "metadata": {},
   "source": [
    "# Class Code of OCRProcessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "942b243e-870c-4bb6-a494-461afb5ed99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict, Any, List, Union\n",
    "import os\n",
    "import base64\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "class OCRProcessors:\n",
    "    def __init__(self, model_name: str = \"llama3.2-vision:11b\", \n",
    "                 base_url: str = \"http://localhost:11434/api/generate\",\n",
    "                 max_workers: int = 1):\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.base_url = base_url\n",
    "        self.max_workers = max_workers\n",
    "\n",
    "    def _encode_image(self, image_path: str) -> str:\n",
    "        \"\"\"Convert image to base64 string\"\"\"\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "    def _preprocess_image(self, image_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Preprocess image before OCR:\n",
    "        - Convert PDF to image if needed\n",
    "        - Auto-rotate\n",
    "        - Enhance contrast\n",
    "        - Reduce noise\n",
    "        \"\"\"\n",
    "\n",
    "        # Read image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Could not read image at {image_path}\")\n",
    "\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Enhance contrast using CLAHE\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        enhanced = clahe.apply(gray)\n",
    "\n",
    "        # Denoise\n",
    "        denoised = cv2.fastNlMeansDenoising(enhanced)\n",
    "\n",
    "        # Auto-rotate if needed\n",
    "        # TODO: Implement rotation detection and correction\n",
    "\n",
    "        # Save preprocessed image\n",
    "        preprocessed_path = f\"{image_path}_preprocessed.jpg\"\n",
    "        cv2.imwrite(preprocessed_path, denoised)\n",
    "\n",
    "        return preprocessed_path\n",
    "\n",
    "    def process_image(self, image_path: str, format_type: str = \"darshdown\", preprocess: bool = True) -> str:\n",
    "        \"\"\"\n",
    "        Process an image and extract text in the specified format\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to the image file\n",
    "            format_type: One of [\"markdown\", \"text\", \"json\", \"structured\", \"key_value\"]\n",
    "            preprocess: Whether to apply image preprocessing\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if preprocess:\n",
    "                image_path = self._preprocess_image(image_path)\n",
    "            \n",
    "            image_base64 = self._encode_image(image_path)\n",
    "            \n",
    "            # Clean up temporary files\n",
    "            if image_path.endswith(('_preprocessed.jpg', '_temp.jpg')):\n",
    "                os.remove(image_path)\n",
    "\n",
    "            # Generic prompt templates for different formats\n",
    "            prompts = {\n",
    "                  \"darshdown\": \"\"\"Extract the text only.\"\"\"\n",
    "            }\n",
    "\n",
    "            # Get the appropriate prompt\n",
    "            prompt = prompts.get(format_type, prompts[\"darshdown\"])\n",
    "\n",
    "            # Prepare the request payload\n",
    "            payload = {\n",
    "                \"model\": self.model_name,\n",
    "                \"prompt\": prompt,\n",
    "                \"stream\": False,\n",
    "                \"images\": [image_base64]\n",
    "            }\n",
    "\n",
    "            # Make the API call to Ollama\n",
    "            response = requests.post(self.base_url, json=payload)\n",
    "            response.raise_for_status()  # Raise an exception for bad status codes\n",
    "            \n",
    "            result = response.json().get(\"response\", \"\")\n",
    "            \n",
    "            # Clean up the result if needed\n",
    "            if format_type == \"json\":\n",
    "                try:\n",
    "                    # Try to parse and re-format JSON if it's valid\n",
    "                    json_data = json.loads(result)\n",
    "                    return json.dumps(json_data, indent=2)\n",
    "                except json.JSONDecodeError:\n",
    "                    # If JSON parsing fails, return the raw result\n",
    "                    return result\n",
    "            \n",
    "            return result\n",
    "        except Exception as e:\n",
    "            return f\"Error processing image: {str(e)}\"\n",
    "\n",
    "    def process_batch(\n",
    "        self,\n",
    "        input_path: Union[str, List[str]],\n",
    "        format_type: str = \"darshdown\",\n",
    "        recursive: bool = False,\n",
    "        preprocess: bool = True\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Process multiple images in batch\n",
    "        \n",
    "        Args:\n",
    "            input_path: Path to directory or list of image paths\n",
    "            format_type: Output format type\n",
    "            recursive: Whether to search directories recursively\n",
    "            preprocess: Whether to apply image preprocessing\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with results and statistics\n",
    "        \"\"\"\n",
    "        # Collect all image paths\n",
    "        image_paths = []\n",
    "        if isinstance(input_path, str):\n",
    "            base_path = Path(input_path)\n",
    "            if base_path.is_dir():\n",
    "                pattern = '**/*' if recursive else '*'\n",
    "                for ext in ['.png', '.jpg', '.jpeg', '.pdf', '.tiff']:\n",
    "                    image_paths.extend(base_path.glob(f'{pattern}{ext}'))\n",
    "            else:\n",
    "                image_paths = [base_path]\n",
    "        else:\n",
    "            image_paths = [Path(p) for p in input_path]\n",
    "\n",
    "        results = {}\n",
    "        errors = {}\n",
    "        \n",
    "        # Process images in parallel with progress bar\n",
    "        with tqdm(total=len(image_paths), desc=\"Processing images\") as pbar:\n",
    "            with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "                future_to_path = {\n",
    "                    executor.submit(self.process_image, str(path), format_type, preprocess): path\n",
    "                    for path in image_paths\n",
    "                }\n",
    "                \n",
    "                for future in concurrent.futures.as_completed(future_to_path):\n",
    "                    path = future_to_path[future]\n",
    "                    try:\n",
    "                        results[str(path)] = future.result()\n",
    "                    except Exception as e:\n",
    "                        errors[str(path)] = str(e)\n",
    "                    pbar.update(1)\n",
    "\n",
    "        return {\n",
    "            \"results\": results,\n",
    "            \"errors\": errors,\n",
    "            \"statistics\": {\n",
    "                \"total\": len(image_paths),\n",
    "                \"successful\": len(results),\n",
    "                \"failed\": len(errors)\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb937a6-1210-4738-8253-3c9ee26975c6",
   "metadata": {},
   "source": [
    "# Implementation of the OCR model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75862086-0751-446b-be78-a21f3c8662a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TO, HOD\n",
      "\n",
      "Subject: Request for subject change from RM to CP\n",
      "\n",
      "Respected sir,\n",
      "\n",
      "I am Shauti Panchal, currently in semester 6th/3rd year in CSE-1, awaiting to request a subject change from Research Methodology (RM) to Competitive Programming (CP) for the current semester.\n",
      "\n",
      "I had already taken RM last semester and now I wish to explore CP to enhance my skills and growth in this field.\n",
      "\n",
      "As I am not opting for placements, I believe this subject will help me focus on courses that align with my personal aspirations.\n",
      "\n",
      "I kindly request your approval for this change.\n",
      "\n",
      "Thank you for your understanding and support.\n"
     ]
    }
   ],
   "source": [
    "# from ollama_ocr import OCRProcessor\n",
    "# Create an instance\n",
    "with tf.device('/GPU:0'):\n",
    "    ocr = OCRProcessorss(model_name='llama3.2-vision:11b')\n",
    "    \n",
    "    # Test with an image (replace with your image path)\n",
    "    result = ocr.process_image(\n",
    "        image_path=\"C:\\\\Users\\\\darsh\\\\Desktop\\\\6th Sem\\\\SGP-IV\\\\Input Images\\\\Sample Image2.jpg\",\n",
    "        format_type=\"darshdown\"\n",
    "    )\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc6f4a0-3196-419f-8673-b9d8a8406d2a",
   "metadata": {},
   "source": [
    "# Batch Wise Implementation for low Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09c8bc3-440a-4595-aa9d-2e042dc29ec4",
   "metadata": {},
   "source": [
    "#### batch wise results will be store into the variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deb3178f-6bd8-4f5a-90b8-35b6dad43f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|████████████████████████████████████████████████████████████████| 1/1 [03:07<00:00, 187.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total': 1, 'successful': 1, 'failed': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test batch processing\n",
    "with tf.device('/GPU:0'):\n",
    "    ocr = OCRProcessors(model_name='llama3.2-vision:11b')\n",
    "    batch_results = ocr.process_batch(\"C:\\\\Users\\\\darsh\\\\Desktop\\\\6th Sem\\\\SGP-IV\\\\Input Images\\\\Sample Image2.jpg\")\n",
    "    print(batch_results['statistics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69d908cd-d402-4883-8697-fbfc5f7d3508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Statistics:\n",
      "Total images: 1\n",
      "Successfully processed: 1\n",
      "Failed: 0\n"
     ]
    }
   ],
   "source": [
    "# Print statistics\n",
    "print(\"\\nProcessing Statistics:\")\n",
    "print(f\"Total images: {batch_results['statistics']['total']}\")\n",
    "print(f\"Successfully processed: {batch_results['statistics']['successful']}\")\n",
    "print(f\"Failed: {batch_results['statistics']['failed']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7df856ca-07f3-4167-985c-9fb9f46084c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: C:\\Users\\darsh\\Desktop\\6th Sem\\SGP-IV\\Input Images\\Sample Image2.jpg\n",
      "--------------------------------------------------\n",
      "Extracted Text: To, HOD,\n",
      "\n",
      "Subject: Request for subject change from RM to CP.\n",
      "\n",
      "Respected sir,\n",
      "\n",
      "I am Shauti Panchal, currently in semester 6th/3rd year in CSE-1. I am writing to request a subject change from Research Methodology (RM) to Competitive Programming (CP) for the current semester.\n",
      "\n",
      "I had already taken RM last semester and now wish to explore CP to enhance my skills and growth in this field.\n",
      "\n",
      "As I am not opting for placements, I believe this subject will help me focus on courses that align with my personal aspirations.\n",
      "\n",
      "I kindly request your approval for this change.\n",
      "\n",
      "Thank you for your understanding and support.\n"
     ]
    }
   ],
   "source": [
    "# Get text from all successfully processed images\n",
    "for file_path, text in batch_results['results'].items():\n",
    "    print(f\"\\nFile: {file_path}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Extracted Text: {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379d23f3-1873-409a-8c60-dc1ace8f12c8",
   "metadata": {},
   "source": [
    "# Removal of Empty Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a11c449-6053-440d-898d-31f19230d9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To, HOD,Subject: Request for subject change from RM to CP.Respected sir,I am Shauti Panchal, currently in semester 6th/3rd year in CSE-1. I am writing to request a subject change from Research Methodology (RM) to Competitive Programming (CP) for the current semester.I had already taken RM last semester and now wish to explore CP to enhance my skills and growth in this field.As I am not opting for placements, I believe this subject will help me focus on courses that align with my personal aspirations.I kindly request your approval for this change.Thank you for your understanding and support.\n"
     ]
    }
   ],
   "source": [
    "# Remove \\n characters\n",
    "cleaned_text = text.replace('\\n', '')\n",
    "\n",
    "# Print the result\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d4328b-31c5-4543-92ee-6ba05033c186",
   "metadata": {},
   "source": [
    "# Evaluation Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c011bd5a-e27d-4f96-a973-7d5fac74c528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darsh\\miniconda3\\envs\\gpu\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned Marks: 8\n",
      "Feedback:\n",
      "- Good match for: 'Subject: Request for Subject Change from RM to CP\n",
      "\n",
      "            Dear HOD,\n",
      "\n",
      "            I am Shauti Panchal, a 6th-semester student in CSE-1'\n",
      "- Good match for: 'I request approval to change my subject from Research Methodology (RM) to Competitive Programming (CP) this semester'\n",
      "- Partial match for: 'Having already taken RM last semester, I wish to explore CP to enhance my skills and align with my aspirations, as I am not opting for placements'\n",
      "- Missing or poor match for: 'Thank you for your consideration'\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"  # Replace if needed\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Function to generate embeddings\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Use mean pooling for embeddings\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.numpy()\n",
    "\n",
    "# Function to compute similarity\n",
    "def compute_similarity(original, student):\n",
    "    original_emb = get_embeddings(original)\n",
    "    student_emb = get_embeddings(student)\n",
    "    return cosine_similarity(original_emb, student_emb)[0][0]\n",
    "\n",
    "# Function to extract key points from reference answer\n",
    "def extract_key_points(reference_answer):\n",
    "    key_points = re.split(r'[.!?]', reference_answer)\n",
    "    return [kp.strip() for kp in key_points if kp.strip()]\n",
    "\n",
    "# Function to check key point coverage\n",
    "def check_key_points_coverage(key_points, student_answer):\n",
    "    coverage = {}\n",
    "    for key_point in key_points:\n",
    "        coverage[key_point] = compute_similarity(key_point, student_answer)\n",
    "    return coverage\n",
    "\n",
    "# Function to assign marks with weighting\n",
    "def assign_marks_with_weighting(coverage, total_marks):\n",
    "    total_weight = sum(coverage.values())\n",
    "    weighted_marks = 0\n",
    "    for key_point, score in coverage.items():\n",
    "        weight = score / total_weight if total_weight > 0 else 1 / len(coverage)\n",
    "        weighted_marks += total_marks * weight * (score if score > 0.5 else 0)\n",
    "    return round(weighted_marks, 2)\n",
    "\n",
    "# Function to calculate penalties\n",
    "def calculate_penalties(student_answer, key_points):\n",
    "    penalties = 0\n",
    "    # Penalize irrelevance: based on length not matching key points\n",
    "    if len(student_answer.split()) > len(\" \".join(key_points).split()) * 1.5:\n",
    "        penalties += 1  # Example penalty for verbosity\n",
    "    # Add more penalty logic as needed\n",
    "    return penalties\n",
    "\n",
    "# Function to generate feedback\n",
    "def generate_feedback(coverage):\n",
    "    feedback = []\n",
    "    for key_point, score in coverage.items():\n",
    "        if score > 0.85:\n",
    "            feedback.append(f\"Good match for: '{key_point}'\")\n",
    "        elif score > 0.5:\n",
    "            feedback.append(f\"Partial match for: '{key_point}'\")\n",
    "        else:\n",
    "            feedback.append(f\"Missing or poor match for: '{key_point}'\")\n",
    "    return feedback\n",
    "\n",
    "# Main evaluation function\n",
    "def evaluate_answer(reference_answer, student_answer, total_marks):\n",
    "    # Step 1: Extract key points from reference answer\n",
    "    key_points = extract_key_points(reference_answer)\n",
    "\n",
    "    # Step 2: Check coverage of key points\n",
    "    coverage = check_key_points_coverage(key_points, student_answer)\n",
    "\n",
    "    # Step 3: Assign marks with weighting\n",
    "    marks = assign_marks_with_weighting(coverage, total_marks)\n",
    "\n",
    "    # Step 4: Apply penalties\n",
    "    penalties = calculate_penalties(student_answer, key_points)\n",
    "    marks -= penalties\n",
    "    marks = max(0, marks)  # Ensure non-negative marks\n",
    "\n",
    "    # Step 5: Generate feedback\n",
    "    feedback = generate_feedback(coverage)\n",
    "\n",
    "    return round(marks), feedback\n",
    "\n",
    "# Testing the implementation\n",
    "if __name__ == \"__main__\":\n",
    "    reference_answer = (\n",
    "        '''Subject: Request for Subject Change from RM to CP\n",
    "\n",
    "            Dear HOD,\n",
    "\n",
    "            I am Shauti Panchal, a 6th-semester student in CSE-1. I request approval to change my subject from Research Methodology (RM) to Competitive Programming (CP) this semester. Having already taken RM last semester, I wish to explore CP to enhance my skills and align with my aspirations, as I am not opting for placements.\n",
    "\n",
    "            Thank you for your consideration.'''\n",
    "    )\n",
    "\n",
    "    r = (\n",
    "        '''Subject: Request for Subject Change from RM to CP\n",
    "\n",
    "            Dear HOD,\n",
    "\n",
    "            I am Shauti Panchal, a 6th-semester student in CSE-1. I request approval to change my subject from Research Methodology (RM) to Competitive Programming (CP) this semester. Having already taken RM last semester, I wish to explore CP to enhance my skills and align with my aspirations, as I am not opting for placements.\n",
    "\n",
    "            Thank you for your consideration.'''\n",
    "    )\n",
    "    \n",
    "    total_marks = 10\n",
    "\n",
    "    # Evaluate the answer\n",
    "    marks, feedback = evaluate_answer(reference_answer, r, total_marks)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Assigned Marks: {marks}\")\n",
    "    print(\"Feedback:\")\n",
    "    for line in feedback:\n",
    "        print(f\"- {line}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6730bc43-6517-4aa6-bcfb-0630134fe97d",
   "metadata": {},
   "source": [
    "# Evaluation Strategy Version-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccc8e6c0-b1aa-405b-9af1-c997e19db775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:\n",
      "BLEU Score: 81.02%\n",
      "SBERT Similarity: 96.12%\n",
      "Redundancy Penalty: 12.00%\n",
      "\n",
      "Feedback:\n",
      "Content Similarity (BLEU): 81.02%\n",
      "Semantic Similarity (SBERT): 96.12%\n",
      "Redundancy Penalty: -12.00%\n",
      "Marks: 9/10\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Load models\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess_text(text):\n",
    "    return re.sub(r'\\s+', ' ', re.sub(r'[^\\w\\s]', '', text.lower())).strip()\n",
    "\n",
    "# Semantic similarity using SBERT\n",
    "def calculate_sbert_similarity(ref, cand):\n",
    "    ref_embedding = sbert_model.encode([ref])[0]\n",
    "    cand_embedding = sbert_model.encode([cand])[0]\n",
    "    similarity = np.dot(ref_embedding, cand_embedding) / (np.linalg.norm(ref_embedding) * np.linalg.norm(cand_embedding))\n",
    "    return similarity\n",
    "\n",
    "# BLEU score calculation\n",
    "def calculate_bleu_similarity(ref, cand):\n",
    "    return sentence_bleu([ref.split()], cand.split(), smoothing_function=SmoothingFunction().method1)\n",
    "\n",
    "# Redundancy penalty\n",
    "def calculate_redundancy_penalty(text):\n",
    "    words = text.split()\n",
    "    unique_words = set(words)\n",
    "    redundancy_ratio = 1 - len(unique_words) / len(words) if words else 0\n",
    "    return max(0, redundancy_ratio - 0.2)  # Allow 20% redundancy\n",
    "\n",
    "# Evaluation\n",
    "def evaluate_response(student_answer, evaluator_answer, weights):\n",
    "    student_answer = preprocess_text(student_answer)\n",
    "    evaluator_answer = preprocess_text(evaluator_answer)\n",
    "    \n",
    "    # BLEU Score\n",
    "    bleu = calculate_bleu_similarity(evaluator_answer, student_answer)\n",
    "    \n",
    "    # SBERT Similarity\n",
    "    sbert_similarity = calculate_sbert_similarity(evaluator_answer, student_answer)\n",
    "\n",
    "    # Redundancy Penalty\n",
    "    redundancy_penalty = calculate_redundancy_penalty(student_answer)\n",
    "    \n",
    "    # Final Scores based on user-defined weights\n",
    "    scores = {\n",
    "        \"BLEU Score\": bleu * 100,\n",
    "        \"SBERT Similarity\": sbert_similarity * 100,\n",
    "        \"Redundancy Penalty\": redundancy_penalty * 100\n",
    "    }\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# Dynamic Mark Calculation\n",
    "def calculate_marks(scores, total_marks=10, weights=None):\n",
    "    if weights is None:\n",
    "        weights = {\n",
    "            \"BLEU Score\": 0.5,  # Default weightage\n",
    "            \"SBERT Similarity\": 0.5,\n",
    "            \"Redundancy Penalty\": -0.1  # Negative weight to reduce marks for redundancy\n",
    "        }\n",
    "    \n",
    "    final_score = sum(scores[aspect] * weight for aspect, weight in weights.items())\n",
    "    marks_obtained = max(0, (final_score / 100) * total_marks)\n",
    "    return round(marks_obtained, 2)\n",
    "\n",
    "# Feedback Generation\n",
    "def generate_feedback(scores, marks_obtained, total_marks, thresholds=None):\n",
    "    if thresholds is None:\n",
    "        thresholds = {\n",
    "            \"SBERT Similarity\": 70,\n",
    "            \"Redundancy Penalty\": 10\n",
    "        }\n",
    "    \n",
    "    feedback = []\n",
    "    feedback.append(f\"Content Similarity (BLEU): {scores['BLEU Score']:.2f}%\")\n",
    "    feedback.append(f\"Semantic Similarity (SBERT): {scores['SBERT Similarity']:.2f}%\")\n",
    "    feedback.append(f\"Redundancy Penalty: -{scores['Redundancy Penalty']:.2f}%\")\n",
    "    feedback.append(f\"Marks: {round(marks_obtained)}/{total_marks}\")\n",
    "    \n",
    "    if scores[\"SBERT Similarity\"] < thresholds[\"SBERT Similarity\"]:\n",
    "        feedback.append(\"Suggestion: Improve semantic alignment with the evaluator's answer.\")\n",
    "    if scores[\"Redundancy Penalty\"] > thresholds[\"Redundancy Penalty\"]:\n",
    "        feedback.append(\"Suggestion: Avoid repeating phrases unnecessarily.\")\n",
    "    \n",
    "    return \"\\n\".join(feedback)\n",
    "\n",
    "# Main Function\n",
    "if __name__ == \"__main__\":\n",
    "    evaluator_answer = '''Extracted Text: To, HOD,\n",
    "\n",
    "    Subject: Request for subject change from RM to CP.\n",
    "    \n",
    "    Respected sir,\n",
    "    \n",
    "    I am Shauti Panchal, currently in semester 6th/3rd year in CSE-1. I am writing to request a subject change from Research Methodology (RM) to Competitive Programming (CP) for the current semester.\n",
    "    \n",
    "    I had already taken RM last semester and now wish to explore CP to enhance my skills and growth in this field.\n",
    "    \n",
    "    As I am not opting for placements, I believe this subject will help me focus on courses that align with my personal aspirations.\n",
    "    \n",
    "    I kindly request your approval for this change.Thank you for your understanding and support.'''\n",
    "    student_answer = '''Extracted Text: To, HOD, Subject: Request for subject change from RM to CP.Respected sir,I am Shauti Panchal, currently in semester 6th/3rd year in CSE-1. I am writing to request a subject change from Research Methodology (RM) to Competitive Programming (CP) for the current semester.I had already taken RM last semester and now wish to explore CP to enhance my skills and growth in this field.As I am not opting for placements, I believe this subject will help me focus on courses that align with my personal aspirations.I kindly request your approval for this change.Thank you for your understanding and support.'''\n",
    "    total_marks = 10\n",
    "\n",
    "    # User-defined evaluation scheme (weights for each aspect)\n",
    "    weights = {\n",
    "        \"BLEU Score\": 0.05,  # Example of adjusting the weight\n",
    "        \"SBERT Similarity\": 0.95,\n",
    "        \"Redundancy Penalty\": -0.2  # More penalty for redundancy\n",
    "    }\n",
    "    \n",
    "    # Custom feedback thresholds (score below this value triggers specific feedback)\n",
    "    thresholds = {\n",
    "        \"SBERT Similarity\": 75,  # Custom threshold for SBERT similarity\n",
    "        \"Redundancy Penalty\": 15  # Custom threshold for redundancy\n",
    "    }\n",
    "\n",
    "    # Evaluate and generate feedback based on the custom evaluation scheme\n",
    "    scores = evaluate_response(student_answer, evaluator_answer, weights)\n",
    "    marks_obtained = calculate_marks(scores, total_marks, weights)\n",
    "    feedback = generate_feedback(scores, marks_obtained, total_marks, thresholds)\n",
    "\n",
    "    print(\"Scores:\")\n",
    "    for aspect, score in scores.items():\n",
    "        print(f\"{aspect}: {score:.2f}%\")\n",
    "    print(\"\\nFeedback:\")\n",
    "    print(feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a188d0-e45d-4c97-aea4-3551a7ae6676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
