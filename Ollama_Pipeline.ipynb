{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77b5ab0b-0c48-4dc7-83fa-ee4f0dffc30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Ollama_OCR_Pipeline.OCR_Processors import OCR_Processors\n",
    "from Ollama_OCR_Pipeline.ResponseEvaluator import ResponseEvaluator\n",
    "from Ollama_OCR_Pipeline.Answer_Evalute import AnswerEvaluator\n",
    "from Ollama_OCR_Pipeline.Question_to_Answer import Question_to_Answer_ChatModel\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7a1da4-cf6b-4e68-afee-7db7f1bdcda8",
   "metadata": {},
   "source": [
    "# Llama 3.2 Pipeline for text Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7f56df7-84e2-4cc8-99d2-4fe03a58e953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|████████████████████████████████████████████████████████████████| 1/1 [02:44<00:00, 164.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TO, HODSubject: Request for subject change from RM to CPRespected sir,I am Shauti Panchal, currently in semester 6th/3rd year in CSE-1. I am writing to request a subject change from Research Methodology (RM) to Competitive Programming (CP) for the current semester.I had already taken RM last semester and now wish to explore CP to enhance my skills and growth in this field. As I am not opting for placements, I believe that focusing on CP will help me align with my personal aspirations.I kindly request your approval for this change.Thank you for your understanding and support.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test batch processing\n",
    "with tf.device('/GPU:0'):\n",
    "    ocr = OCR_Processors(model_name='llama3.2-vision:11b')\n",
    "    batch_results = ocr.process_batch(\"C:\\\\Users\\\\darsh\\\\Desktop\\\\6th Sem\\\\SGP-IV\\\\Input Images\\\\Sample Image2.jpg\")\n",
    "    # Get text from all successfully processed images\n",
    "    for file_path, text in batch_results['results'].items():\n",
    "        # Remove \\n characters\n",
    "        cleaned_text = text.replace('\\n', '')\n",
    "        \n",
    "        # Print the result\n",
    "        print(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee28679-8ffd-44a0-9267-55001b8e48f1",
   "metadata": {},
   "source": [
    "# Evaluator Version-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "386c2ca7-3161-4e97-b833-4b41f15c5a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darsh\\miniconda3\\envs\\gpu\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned Marks: 8\n",
      "Feedback:\n",
      "- Good match for: 'Subject: Request for Subject Change from RM to CP\n",
      "    Dear HOD,\n",
      "    I am Shauti Panchal, a 6th-semester student in CSE-1'\n",
      "- Good match for: 'I request approval to change my subject \n",
      "    from Research Methodology (RM) to Competitive Programming (CP) this semester'\n",
      "- Partial match for: 'Having already \n",
      "    taken RM last semester, I wish to explore CP to enhance my skills and align with my aspirations, \n",
      "    as I am not opting for placements'\n",
      "- Missing or poor match for: 'Thank you for your consideration'\n"
     ]
    }
   ],
   "source": [
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "# Initialize the evaluator\n",
    "evaluator = AnswerEvaluator(model_name)\n",
    "\n",
    "# Reference and student answers\n",
    "reference_answer = (\n",
    "    \"\"\"Subject: Request for Subject Change from RM to CP\n",
    "    Dear HOD,\n",
    "    I am Shauti Panchal, a 6th-semester student in CSE-1. I request approval to change my subject \n",
    "    from Research Methodology (RM) to Competitive Programming (CP) this semester. Having already \n",
    "    taken RM last semester, I wish to explore CP to enhance my skills and align with my aspirations, \n",
    "    as I am not opting for placements.\n",
    "    Thank you for your consideration.\"\"\"\n",
    ")\n",
    "\n",
    "# Total marks for the evaluation\n",
    "total_marks = 10\n",
    "\n",
    "# Evaluate the answer\n",
    "marks, feedback = evaluator.evaluate_answer(reference_answer, cleaned_text, total_marks)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Assigned Marks: {marks}\")\n",
    "print(\"Feedback:\")\n",
    "for line in feedback:\n",
    "    print(f\"- {line}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387730da-7046-4ee1-9c2f-71ee659281b3",
   "metadata": {},
   "source": [
    "# Grading System "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bd7a825-2c18-466d-91f5-4cdaea95d86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " The rapid advancement of technology has profoundly reshaped human interaction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: {'BLEU Score': 100.0, 'SBERT Similarity': 100.0, 'Redundancy Penalty': 0}\n",
      "\n",
      "Feedback:\n",
      " Content Similarity (BLEU): 100.00%\n",
      "Semantic Similarity (SBERT): 100.00%\n",
      "Redundancy Penalty: -0.00%\n",
      "Marks: 10/10\n"
     ]
    }
   ],
   "source": [
    "evaluator = ResponseEvaluator(model_name='all-MiniLM-L6-v2')\n",
    "\n",
    "# input from the faculty:\n",
    "faculty_answer = input()\n",
    "\n",
    "#example test case:\n",
    "# student_answer = \"Technology has dramatically transformed the way we interact with the world.\"\n",
    "# cleaned_text = \"The rapid advancement of technology has profoundly reshaped human interaction.\"\n",
    "\n",
    "weights = {\n",
    "    \"BLEU Score\": 0.05,\n",
    "    \"SBERT Similarity\": 0.95,\n",
    "    \"Redundancy Penalty\": -0.2\n",
    "}\n",
    "\n",
    "scores = evaluator.evaluate_response(faculty_answer, cleaned_text, weights)\n",
    "marks_obtained = evaluator.calculate_marks(scores, total_marks=10, weights=weights)\n",
    "feedback = evaluator.generate_feedback(scores, marks_obtained, total_marks=10)\n",
    "\n",
    "print(\"Scores:\", scores)\n",
    "print(\"\\nFeedback:\\n\", feedback)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6c11cb-a6a4-4461-a599-e7317e37c03f",
   "metadata": {},
   "source": [
    "# Faculty Question gpt-neo-1.3B comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c27f628-ea59-4263-b731-c7d5c9c90002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9cc9ffdfe684508b9c21173cc799dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  67%|######7   | 3.58G/5.31G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0abeaf9ed84f279930271a4ef34a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04aae94151da42f499108a787b0977ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56bb2880ff746088bcd6ccb9a94f199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ff691d05bd24ad4ac4f7e352617e825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"EleutherAI/gpt-neo-1.3B\"\n",
    "\n",
    "chat_model = Question_to_Answer_ChatModel(model_name)\n",
    "faculty_question = input(\"\\nEnter your question: \")\n",
    "generated_answer = chat_model.generate_answer(faculty_question)\n",
    "\n",
    "# Store answer in a variable\n",
    "stored_answer = generated_answer\n",
    "\n",
    "# Display the answer\n",
    "print(\"\\nGenerated Answer:\", stored_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c43e18-0b0a-46e1-9f12-1c6f4df3888c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
